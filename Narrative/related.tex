\section{Related work}

\emph{Here we describe related studies.}

Baker et al. \cite{baker} investigated the use of data compression techniques on climate simulation data from CESM \cite{cesm}. They developed an approach for verifying the climate data and used it to evaluate several compression algorithms, including FPZIP \cite{fpzip}, ISABELA, APAX, and GRIB2 (with JPEG2000 compression). The verification process included (1) quantifying the difference between the original and reconstructed data sets via measures of pointwise error, average error (RMSE and NRMSE), and Pearson correlation and (2) evaluating the reconstructed data in the context of an ensemble of CESM runs with slight perturbations by a CESM port verification tool (CESM-PVT). They determined that the diversity of the climate data requires individual treatment of variables and that the reconstructed data can fall within the natural variability of the system.
Laney et al. \cite{laney2014assessing} examined the effects of lossy compression in physics simulations by evaluating two lossy compressors (FPZIP and APAX \cite{apax}) in three physics simulation codes. They used physics-based metrics for each simulation to assess the impact of lossy compression. They noted that the characteristics of the compression error must be carefully considered in the context of the underlying physics being modeled.
Lakshminarasimhan et  al. \cite{isabela} propose the ISABELA lossy compressor. It performs data compression by B-spline interpolation after sorting the data series. They evaluated the performance of ISABELA with several metrics: compression ratio, maximum compression error (pointwise relative error), average compression error (NRMSE), and compression time. They also evaluated the compressed data by quantitative analysis and visual analysis. In quantitative analysis, they evaluated the Pearson correlation of different data regions and the difference of derived data. In visual analysis, they utilized the visualization tool to present the original data and ISABELA-compressed data.
Lindstrom \cite{zfp} proposed a lossy compression algorithm for floating-point arrays in fixed rate (i.e. ZFP) and evaluated ZFP of rate-distortion, rate speed, density spectrum, and derivatives (Morse segmentation of gradients) in several applications, including quantitative and visual analysis, visualization, and fluid dynamics simulation.
Sasaki et al. \cite{ssem} proposed a lossy compression method (i.e. SSEM) based on wavelet transform and vector quantization. They applied their compression method to a checkpoint/restart technique and evaluate the impact on results of a production climate application (NICAM).
Di and Cappello \cite {sz} proposed an error-bounded lossy compressor (i.e. SZ) based on curve-fitting and binary representation analysis. They evaluated SZ with the metrics including the maximum compression error (bounded or not bounded), compression ratio, and compression/decompression speed.

